
- Artificial neural networks (ANNs)
	- Machine learning models inspired by the networks of biological neurons found in our brains
- ANNs are the core of deep learning
- TensorFlow's Keras API
	- Building
	- Training
	- Evaluating
	- Running neural networks

# From Biological to Artificial Neurons

- ANNs were first introduced in 1943 by neurophysiologist Warren McCulloch and Walter Pitts
- Simplified computational model of how biological neurons might work to perform complex computations using propositional logic
- Connectionism (1980s), the study of neural networks
- Support vector machines (1990s)

Renewed ANNs
- Huge amount of data available to train neural networks
- ANNs outperform other ML techniques on large and complex problems
- Increase in computing power
	- Moore's law
	- GPU
	- Cloud platforms
- Training algorithms have been improved
- Theroretical limitations of ANNs have tunred out to be 

## Biological Neurons
## Logical Computations with Neurons
## The Perceptron
## The Multiplayer Perceptron and Backpropagation
## Regression MLPs
## Classification MLPs

# Implementing MLPs with Keras

## Building an Image Classifier Using the Sequential API
## Building a Regression MLP Using the Sequential API
## Building Complex Models Using the Functional API
## Using the Subclassing API to Build Dynamic Models
## Saving and Restoring a Model
## Using Callbacks

## Using TensorBoard for Visualization

# Fine-Tuning Neural Network Hyperparameters

## Number of Hidden Layers
## Number of Neurons per Hidden Layer
## Learning rate, Batch Size, and Other Hyperparameters

