# Serving a TensorFlow Model

## Using TensorFlor Serving
## Creating a Prediction Service on Vertex AI
## Running Batch Prediction Jobs on Vertex AI

# Deploying a Model to a Mobile or Embedded Device

# Running a Model in a Web Page

# Using GPUs to Speed Up Computations

## Getting Your Own GPU
## Managing the GPU RAM
## Placing Operations and Variables on Devices
## Parallel Execution Across Multiple Devices

# Training Models Across Multiple Devices

## Model Parallelism
## Data Parallelism
## Training at Scale Using the Distribution Strategies API
## Training a Model on a TensorFlow Cluster
## Running Larger Training Jobs on Vertex AI
## Hyperparameter Tuning on Vertex AI