# A Simple Model Server

# The Downside of Model Deployments with Python-Based APIs
# TensorFlow Serving

# TensorFlow Architecture Overview

# Exporting Models for TensorFlow Serving

# Model Signatures

# Inspecting Exported Models

# Setting Up TensorFlow Serving

## Docker Installation
## Native Ubuntu Installation
## Building TensorFlow Serving From Source

# Configuring a TensorFlow Server

# REST vs gRPC

# Making Predictions rom the Model Server

## Getting Model Predictions via REST
## Using TensorFlow Serving via gRPC

# Model A/B Testing with TensorFlow Serving

## REST Request for Model Metadata

## gRPC Request for Model Metadata

# Batching Inference Requests

# Other TensorFlow Serving Optimizations

# TensorFlow Serving Optimizations

# TensorFlow Serving Alternatives

## BentoML
## Seldon
## GraphPipe
## Simple TensorFlow Serving
## MLflow
## Ray Serve

# Deploying with Cloud Providers

## Use Cases
## Example Deployment with GCP

# Model Deployment with TFX Pipelines

# Summary